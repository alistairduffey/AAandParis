{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "36d1b35b-0d9a-41ba-916c-6fec75d0c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v5: change hadcrut to C&W\n",
    "# v9: add constant offset method for adjusting cmip6 temps\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "def make_df(path):\n",
    "    all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def get_baseline(df, t_bnds=[1850, 1900], monthly=False, multi_ens=False):\n",
    "    df_hist = df[df['Experiment']=='historical']\n",
    "    \n",
    "    df_hist = df_hist[(df_hist['year'] > t_bnds[0]) & (df_hist['year'] < t_bnds[1])]\n",
    "    \n",
    "    df_hist['base_t_bnds'] = str(t_bnds[0]) + '-' + str(t_bnds[1])\n",
    "    if monthly:\n",
    "        df_hist = df_hist.groupby(['Model', 'base_t_bnds', 'Month']).mean().reset_index().rename(columns=baseline_name_changes)\n",
    "    else:\n",
    "        if multi_ens:\n",
    "            df_hist = df_hist.groupby(['Model', 'Ensemble_member', 'base_t_bnds']).mean().reset_index().rename(columns=baseline_name_changes)\n",
    "        else:\n",
    "            df_hist = df_hist.groupby(['Model', 'base_t_bnds']).mean().reset_index().rename(columns=baseline_name_changes)\n",
    "    df_hist = df_hist.drop(columns=['year'])\n",
    "    return df_hist\n",
    "\n",
    "def wmean(df, values, weights):\n",
    "    return sum(df[weights]*df[values])/df[weights].sum()\n",
    "\n",
    "def preprocess_hadcrut_z(df, window, preind_period=[1850,1900]):\n",
    "    \"\"\" hadcrut analysis annual means tas data is donwloaded as anomaly relative to the period \n",
    "        1961-1990, (see description here: https://www.metoffice.gov.uk/hadobs/hadcrut5/data/current/download.html)\n",
    "        we preprocess by re-baselining this to be anomaly relative to our preindustrial period, 1850-1900\"\"\n",
    "    \n",
    "    returns df with tas relative to pre-industrial mean \"\"\"\n",
    "    df.rename(columns={'Time':'Year'}, inplace=True)\n",
    "    df_pre_ind = df[df['Year'].between(preind_period[0], preind_period[1])]\n",
    "    offset = df_pre_ind['Anomaly (deg C)'].mean()\n",
    "    df_out = df[['Year', 'Anomaly (deg C)']]\n",
    "    df_out['Anomaly (deg C)'] = df_out['Anomaly (deg C)'] - offset\n",
    "    df_out['Anomaly (deg C)'] = df_out['Anomaly (deg C)'].rolling(window, center=True).mean()\n",
    "    return df_out\n",
    "\n",
    "def preprocess_obs(df, window, preind_period=[1850,1900]):\n",
    "    \"\"\" hadcrut analysis annual means tas data is donwloaded as anomaly relative to the period \n",
    "        1961-1990, (see description here: https://www.metoffice.gov.uk/hadobs/hadcrut5/data/current/download.html)\n",
    "        we preprocess by re-baselining this to be anomaly relative to our preindustrial period, 1850-1900\"\"\n",
    "    \n",
    "    returns df with tas relative to pre-industrial mean \"\"\"\n",
    "    #df.rename(columns={'Time':'Year'}, inplace=True)\n",
    "    df_pre_ind = df[df['year'].between(preind_period[0], preind_period[1])]\n",
    "    offset_w = df_pre_ind['world_tas'].mean()\n",
    "    offset_na = df_pre_ind['no_arctic_tas'].mean()\n",
    "    df_out = df.copy()\n",
    "    df_out['world_tas'] = df_out['world_tas'] - offset_w\n",
    "    df_out['no_arctic_tas'] = df_out['no_arctic_tas'] - offset_na\n",
    "    df_out['world_tas'] = df_out['world_tas'].rolling(window, center=True).mean()\n",
    "    df_out['no_arctic_tas'] = df_out['no_arctic_tas'].rolling(window, center=True).mean()\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "13019340-9e31-484a-8ed4-375c49642cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "### set up and read in temp data\n",
    "\n",
    "out_dfs = {}\n",
    "\n",
    "## models\n",
    "baseline_name_changes = {'no_arctic_tas':'no_arctic_base_tas',\n",
    "                         'world_tas':'world_base_tas',\n",
    "                        }\n",
    "window=10\n",
    "\n",
    "#exp='ssp370'\n",
    "exp='ssp245'\n",
    "#exp='ssp126'\n",
    "\n",
    "\n",
    "temp_correction_method = 'scale' #options are 'scale' or 'offset'\n",
    "\n",
    "\n",
    "## observations\n",
    "CW_file = 'int_outputs/temperature_CW/CW_tas.csv'\n",
    "\n",
    "Obs_df = preprocess_obs(pd.read_csv(CW_file), window=window)\n",
    "obs_set = 'Cowtan & Way'\n",
    "\n",
    "\n",
    "### initial processing, add baseline temp to each model, \n",
    "### only keep those models with a historic scenario available\n",
    "### define one tas_df used for both plots, this contains all ensemble members\n",
    "\n",
    "in_folder_tas = 'int_outputs/temperature_multi_ens/'\n",
    "\n",
    "tas_df = make_df(in_folder_tas)\n",
    "tas_df = tas_df[tas_df['Experiment'].isin(['historical', exp])]\n",
    "\n",
    "tas_df = tas_df.groupby(['year', 'Experiment', 'Model', 'Ensemble_member']).mean().reset_index() \n",
    "\n",
    "base_tas_df = get_baseline(tas_df, [1850, 1900], multi_ens=True)\n",
    "\n",
    "tas_df = pd.merge(tas_df, base_tas_df, how='left', on=['Model', 'Ensemble_member'])\n",
    "tas_df['no_arctic_tas_anom'] = tas_df['no_arctic_tas'] - tas_df['no_arctic_base_tas']\n",
    "tas_df['world_tas_anom'] = tas_df['world_tas'] - tas_df['world_base_tas']\n",
    "\n",
    "models = tas_df[tas_df['Experiment']==exp]['Model'].unique()\n",
    "tas_df = tas_df[tas_df['Model'].isin(models)]\n",
    "tas_df = tas_df.dropna()\n",
    "\n",
    "models = tas_df['Model'].unique()\n",
    "print(len(models))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "fb52bd1e-e045-4f02-a8af-464e6afc554b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_526/4258750893.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_to_append = tas_df[tas_df['Model'].isin(remaining_models)][tas_df['Ensemble_member']==member_labels_to_try[i]]\n",
      "/tmp/ipykernel_526/4258750893.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_to_append = tas_df[tas_df['Model'].isin(remaining_models)][tas_df['Ensemble_member']==member_labels_to_try[i]]\n",
      "/tmp/ipykernel_526/4258750893.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_to_append = tas_df[tas_df['Model'].isin(remaining_models)][tas_df['Ensemble_member']==member_labels_to_try[i]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "43\n",
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_526/4258750893.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_to_append = tas_df[tas_df['Model'].isin(remaining_models)][tas_df['Ensemble_member']==member_labels_to_try[i]]\n",
      "/tmp/ipykernel_526/4258750893.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_to_append = tas_df[tas_df['Model'].isin(remaining_models)][tas_df['Ensemble_member']==member_labels_to_try[i]]\n",
      "/tmp/ipykernel_526/4258750893.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_to_append = tas_df[tas_df['Model'].isin(remaining_models)][tas_df['Ensemble_member']==member_labels_to_try[i]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### define a first ensemble member version of tas_df\n",
    "\n",
    "# this (somewhat hacky) code tries ensemble members in the order below ...\n",
    "# to see what label the first member for each model has\n",
    "member_labels_to_try = ['r1i1p1f1', 'r2i1p1f1', 'r1i1p2f1', 'r1i1p1f2', 'r1i2p1f1', 'r1i1p1f3', 'r4i1p1f1']\n",
    "\n",
    "tas_df_1st_mem = tas_df[tas_df['Ensemble_member']==member_labels_to_try[0]]\n",
    "for model in models:\n",
    "    df_test =  tas_df_1st_mem[tas_df_1st_mem['Model']==model]\n",
    "    if not exp in df_test['Experiment'].unique() or not 'historical' in df_test['Experiment'].unique():\n",
    "        tas_df_1st_mem.drop(tas_df_1st_mem[tas_df_1st_mem['Model']==model].index, inplace=True)\n",
    "models_1st_mem = tas_df_1st_mem['Model'].unique()\n",
    "remaining_models = set(models).difference(models_1st_mem)\n",
    "print(len(remaining_models))\n",
    "\n",
    "i=1\n",
    "for i in range(1,len(member_labels_to_try)):    \n",
    "    df_to_append = tas_df[tas_df['Model'].isin(remaining_models)][tas_df['Ensemble_member']==member_labels_to_try[i]]\n",
    "    tas_df_1st_mem = pd.concat([tas_df_1st_mem, df_to_append])\n",
    "\n",
    "    for model in models:\n",
    "        df_test =  tas_df_1st_mem[tas_df_1st_mem['Model']==model]\n",
    "        if not exp in df_test['Experiment'].unique() or not 'historical' in df_test['Experiment'].unique():\n",
    "            tas_df_1st_mem.drop(tas_df_1st_mem[tas_df_1st_mem['Model']==model].index, inplace=True)\n",
    "\n",
    "    models_1st_mem = tas_df_1st_mem['Model'].unique()\n",
    "    remaining_models = set(models).difference(models_1st_mem)\n",
    "\n",
    "    print(len(remaining_models))\n",
    "    i=i+1\n",
    "#print(remaining_models)\n",
    "print(len(tas_df_1st_mem['Model'].unique()))\n",
    "print(len(tas_df_1st_mem[tas_df_1st_mem['year']==1850]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642322b-ae16-426a-a554-c1e928c26c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f7e2b4-af80-4896-8cbd-2b1a73415735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E3SM-1-1\n",
      "65067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_526/2274232232.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_test = tas_df[tas_df['Model']==model][tas_df['Ensemble_member']==ens]\n",
      "/tmp/ipykernel_526/2274232232.py:16: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  tas_df.drop(tas_df[tas_df['Model']==model][tas_df['Ensemble_member']==ens].index, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "### drop model E3SM-1-1 as the run only goes to 2024\n",
    "for model in models:\n",
    "    df_test = tas_df_1st_mem[tas_df_1st_mem['Model']==model]\n",
    "    #print(df_test.year.max())\n",
    "    if df_test.year.max() < 2099:\n",
    "        print(model)\n",
    "        tas_df_1st_mem.drop(tas_df_1st_mem[tas_df_1st_mem['Model']==model].index, inplace=True)\n",
    "\n",
    "### drop ensemble members which only have a historical run from tas_df\n",
    "print(len(tas_df))\n",
    "for model in models:\n",
    "    for ens in tas_df[tas_df['Model']==model]['Ensemble_member'].unique():\n",
    "        df_test = tas_df[tas_df['Model']==model][tas_df['Ensemble_member']==ens]\n",
    "        if not exp in df_test['Experiment'].unique():\n",
    "            #print(model+ens+'  no ssp245')\n",
    "            tas_df.drop(tas_df[tas_df['Model']==model][tas_df['Ensemble_member']==ens].index, inplace=True)\n",
    "print(len(tas_df))\n",
    "\n",
    "### check whether any ensemble members are incomplete\n",
    "for model in models:\n",
    "    for ens in tas_df[tas_df['Model']==model]['Ensemble_member'].unique():\n",
    "        df_test = tas_df[tas_df['Model']==model][tas_df['Ensemble_member']==ens]\n",
    "        if df_test.year.max() < 2099:\n",
    "            #print(model+ens + '  incomplete')\n",
    "            tas_df.drop(tas_df[tas_df['Model']==model][tas_df['Ensemble_member']==ens].index, inplace=True)\n",
    "print(len(tas_df))\n",
    "\n",
    "## update models to represent the final list of 42\n",
    "models = tas_df['Model'].unique()\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c9307-7082-494d-a881-f6b761194c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_warming_obs = float(Obs_df.dropna().tail(1)['world_tas'])\n",
    "no_arctic_warming_obs = float(Obs_df.dropna().tail(1)['no_arctic_tas'])\n",
    "\n",
    "obs_year = int(Obs_df.dropna().tail(1)['year'])\n",
    "\n",
    "\n",
    "for temp_thresh in [1.5, 2]:\n",
    "\n",
    "    Model = []\n",
    "    No_arctic = []\n",
    "    World = []\n",
    "    \n",
    "    M_df = pd.DataFrame(columns=tas_df_1st_mem.columns)\n",
    "\n",
    "    blues = []\n",
    "    reds = []\n",
    "    years = []\n",
    "\n",
    "    for m in models:\n",
    "        #print(m)\n",
    "        m_df = tas_df_1st_mem[tas_df_1st_mem['Model']==m] #use the 1st ens mem only df\n",
    "        \n",
    "        m_df['rolling_world_anom'] = m_df['world_tas_anom'].rolling(window, center=True).mean()\n",
    "        m_df['rolling_no_arctic_anom'] = m_df['no_arctic_tas_anom'].rolling(window, center=True).mean()\n",
    "\n",
    "        ratio_w = (m_df[m_df['year']==obs_year]['rolling_world_anom']/global_warming_obs).values[0]\n",
    "        ratio_na = (m_df[m_df['year']==obs_year]['rolling_no_arctic_anom']/no_arctic_warming_obs).values[0]\n",
    "\n",
    "        offset_w = (m_df[m_df['year']==obs_year]['rolling_world_anom'] - global_warming_obs).values[0]\n",
    "        offset_na = (m_df[m_df['year']==obs_year]['rolling_no_arctic_anom'] - no_arctic_warming_obs).values[0]\n",
    "        \n",
    "        if temp_correction_method == 'scale':\n",
    "            m_df['adjusted_world_tas_anom']= (m_df['rolling_world_anom']/ratio_w)\n",
    "            m_df['adjusted_no_arctic_tas_anom']= (m_df['rolling_no_arctic_anom']/ratio_na)\n",
    "        elif temp_correction_method == 'offset':\n",
    "            m_df['adjusted_world_tas_anom']= (m_df['rolling_world_anom'] - offset_w)\n",
    "            m_df['adjusted_no_arctic_tas_anom']= (m_df['rolling_no_arctic_anom'] - offset_na)\n",
    "            \n",
    "        m_df_plot = m_df[m_df['year'] >= obs_year]\n",
    "\n",
    "        blues.append(np.array(m_df_plot['adjusted_world_tas_anom']))\n",
    "        reds.append(np.array(m_df_plot['adjusted_no_arctic_tas_anom']))\n",
    "        years.append(np.array(m_df_plot['year']))\n",
    "\n",
    "    #         M_df = M_df.append(m_df, ignore_index = True) # Replaced with modern pandas below\n",
    "        M_df = pd.concat([M_df,m_df],axis=0)\n",
    "\n",
    "        #also calc crossings\n",
    "        # if no crossing by 2100 (which is the case for Fgoals-g3 under ssp245) extrapolate using linregress for last 20 years\n",
    "        \n",
    "        no_arctic_crossing_year = np.interp(temp_thresh, m_df['adjusted_no_arctic_tas_anom'], m_df['year'])\n",
    "        if np.isnan(no_arctic_crossing_year): #extrapolate\n",
    "            if not exp == 'ssp126': #don't extrapolate ssp126\n",
    "                print(m + ' doesnt cross {} without arctic'.format(temp_thresh))\n",
    "                m_df_regress = m_df[m_df['year'] > 2080].dropna()\n",
    "                regression = stats.linregress(m_df_regress['year'], m_df_regress['adjusted_no_arctic_tas_anom'])\n",
    "                no_arctic_crossing_year = (temp_thresh - regression[1])/regression[0]\n",
    "                print('extrapolated crossing year: {}'.format(str(no_arctic_crossing_year)))\n",
    "            \n",
    "        world_crossing_year = np.interp(temp_thresh, m_df['adjusted_world_tas_anom'], m_df['year'])\n",
    "\n",
    "        Model.append(m)\n",
    "        No_arctic.append(np.round(no_arctic_crossing_year,3))\n",
    "        World.append(np.round(world_crossing_year,3))\n",
    "\n",
    "    out_df = pd.DataFrame({'Model':Model,\n",
    "                           'No_arctic_crossing_year':No_arctic,\n",
    "                           'World_crossing_year':World})\n",
    "    out_df['gap'] = out_df['No_arctic_crossing_year'] - out_df['World_crossing_year']\n",
    "    \n",
    "    out_dfs[temp_thresh] = out_df\n",
    "\n",
    "    #mm_mean_df = out_df.groupby()\n",
    "\n",
    "    ## add observations:\n",
    "    \n",
    "    print('observation year: ' + str(obs_year))\n",
    "    print('{} temp in obs_year:'.format(obs_set) + str(global_warming_obs))\n",
    "    print('{} temp without AA in obs_year:'.format(obs_set) + str(no_arctic_warming_obs))\n",
    "    print('AA contrib:' + str((global_warming_obs-no_arctic_warming_obs)))\n",
    "    print('AA contrib (%)' + str((global_warming_obs-no_arctic_warming_obs)/global_warming_obs))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Obs_df['year'], Obs_df['world_tas'], c='blue', \n",
    "         linestyle='--', label='Observations')\n",
    "plt.plot(Obs_df['year'], Obs_df['no_arctic_tas'], c='red', \n",
    "         linestyle='--', label='Observations without AA')\n",
    "\n",
    "\n",
    "for i in range(len(blues)):\n",
    "    plt.plot(years[i], blues[i],\n",
    "             c='b', alpha=0.5, linewidth=0.5, label='CMIP6')\n",
    "    plt.plot(years[i], reds[i], \n",
    "             c='r', alpha=0.5, linewidth=0.5, label='CMIP6 without AA')\n",
    "\n",
    "\n",
    "plt.xlim(2000,2065)\n",
    "plt.ylim(0.7, 2.7)\n",
    "plt.axhline(2, color='gray')\n",
    "plt.axhline(1.5, color='gray')\n",
    "plt.ylabel('TAS anomaly (째C)')\n",
    "plt.savefig('Figures/tas_projections.png', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20521f0-659d-4960-aade-dca64da99f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep_m_df = ['year', 'Experiment', 'Model', 'adjusted_world_tas_anom', 'adjusted_no_arctic_tas_anom']\n",
    "M_df = M_df[cols_to_keep_m_df]\n",
    "\n",
    "M_df.to_csv('Outputs/master_df_temp_projections_{r}yr_rolling_{scenario}.csv'.format(r=window, scenario=exp))\n",
    "Obs_df.to_csv('Outputs/Processed_{o}_{r}yr_rolling.csv'.format(o=obs_set, r=window))\n",
    "\n",
    "mean = str(np.round(out_df['gap'].mean(), 2))\n",
    "standard_error = str(np.round(out_df['gap'].sem(), 2))\n",
    "print('mean gap for crossing {}C: '.format(temp_thresh)+mean+' +- '+standard_error+' years')\n",
    "out_df.to_csv('Outputs/crossing_years_adjusted_{r}yr_rolling_{e}_{t}C_thresh.csv'.format(r=window, e=exp, t=temp_thresh))\n",
    "#out_dfs[temp_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70da7d5-ee73-4fff-a146-1ccfef312c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(M_df[M_df['Model'] == 'FGOALS-g3'].dropna()['year'], \n",
    "#         M_df[M_df['Model'] == 'FGOALS-g3'].dropna()['adjusted_no_arctic_tas_anom'])\n",
    "#plt.xlim(2050, 2100)\n",
    "#plt.ylim(1.5, 2)\n",
    "#out_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0d208-5af2-44bb-aabb-bebd08052106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca7392-b71a-4a30-b64f-737b39060428",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now repeat calc with multiple ensemble members\n",
    "\n",
    "# take 1.5C as threshold for this plot if using sp126\n",
    "if exp == 'ssp126':\n",
    "    temp_thresh = 1.5\n",
    "    \n",
    "\n",
    "Model = []\n",
    "Ensemble_member = []\n",
    "No_arctic = []\n",
    "World = []\n",
    "for m in models:\n",
    "    m_df = tas_df[tas_df['Model']==m]\n",
    "    ens_mems = m_df[m_df['Experiment']==exp]['Ensemble_member'].unique()\n",
    "    #print(m)\n",
    "    for e in ens_mems:\n",
    "        #print(e)\n",
    "    \n",
    "        me_df = m_df[m_df['Ensemble_member']==e]\n",
    "        me_df.sort_values(by='year', axis=0)\n",
    "\n",
    "        me_df['rolling_world_anom'] = me_df['world_tas_anom'].rolling(window, center=True).mean()\n",
    "        me_df['rolling_no_arctic_anom'] = me_df['no_arctic_tas_anom'].rolling(window, center=True).mean()\n",
    "\n",
    "        try:\n",
    "            ratio_w = (me_df[me_df['year']==obs_year]['rolling_world_anom']/global_warming_obs).values[0]\n",
    "            ratio_na = (me_df[me_df['year']==obs_year]['rolling_no_arctic_anom']/no_arctic_warming_obs).values[0]\n",
    "        \n",
    "            offset_w = (me_df[me_df['year']==obs_year]['rolling_world_anom'] - global_warming_obs).values[0]\n",
    "            offset_na = (me_df[me_df['year']==obs_year]['rolling_no_arctic_anom'] - no_arctic_warming_obs).values[0]        \n",
    "        except:\n",
    "            print('error on: ' + m + e)\n",
    " \n",
    "        if temp_correction_method == 'scale':\n",
    "            me_df['adjusted_world_tas_anom']= (me_df['rolling_world_anom']/ratio_w)\n",
    "            me_df['adjusted_no_arctic_tas_anom']= (me_df['rolling_no_arctic_anom']/ratio_na)\n",
    "        elif temp_correction_method == 'offset':\n",
    "            me_df['adjusted_world_tas_anom']= (me_df['rolling_world_anom'] - offset_w)\n",
    "            me_df['adjusted_no_arctic_tas_anom']= (me_df['rolling_no_arctic_anom'] - offset_na) \n",
    "            \n",
    "        \n",
    "        no_arctic_crossing_year = np.interp(temp_thresh, me_df['adjusted_no_arctic_tas_anom'], me_df['year'])\n",
    "        if np.isnan(no_arctic_crossing_year): #extrapolate\n",
    "            if not exp == 'ssp126': #don't extrapolate ssp126\n",
    "                print(m + e + ' doesnt cross {} without arctic'.format(temp_thresh))\n",
    "                me_df_regress = me_df[me_df['year'] > 2080].dropna()\n",
    "                regression = stats.linregress(me_df_regress['year'], me_df_regress['adjusted_no_arctic_tas_anom'])\n",
    "                no_arctic_crossing_year = (temp_thresh - regression[1])/regression[0]\n",
    "                print('extrapolated crossing year: {}'.format(str(no_arctic_crossing_year)))\n",
    "            \n",
    "        \n",
    "        world_crossing_year = np.interp(temp_thresh, me_df['adjusted_world_tas_anom'], me_df['year'])\n",
    "        if np.isnan(world_crossing_year): #extrapolate\n",
    "            if not exp == 'ssp126': #don't extrapolate ssp126 \n",
    "                print(m + e + ' doesnt cross {}'.format(temp_thresh))\n",
    "                me_df_regress = me_df[me_df['year'] > 2080].dropna()\n",
    "                regression = stats.linregress(me_df_regress['year'], me_df_regress['adjusted_world_tas_anom'])\n",
    "                world_crossing_year = (temp_thresh - regression[1])/regression[0]\n",
    "                print('extrapolated crossing year (world): {}'.format(str(no_arctic_crossing_year)))\n",
    "            \n",
    "        \n",
    "        Model.append(m)\n",
    "        No_arctic.append(np.round(no_arctic_crossing_year,3))\n",
    "        World.append(np.round(world_crossing_year,3))\n",
    "        Ensemble_member.append(e)\n",
    "            \n",
    "\n",
    "out_df_ME = pd.DataFrame({'Model':Model,\n",
    "                          'Ensemble_member':Ensemble_member,\n",
    "                       'No_arctic_crossing_year':No_arctic,\n",
    "                       'World_crossing_year':World})\n",
    "out_df_ME['gap'] = out_df_ME['No_arctic_crossing_year'] - out_df_ME['World_crossing_year']\n",
    "\n",
    "out_df_ME_all = out_df_ME.copy()\n",
    "out_df_ME_all.to_csv('Outputs/Crossing_years_multi_ensemble_mems_{r}yr_rolling_{e}_{t}C_thresh.csv'.format(r=window, e=exp, t=temp_thresh))\n",
    "## keep only models with more than x ensemble members:\n",
    "ens_members_needed = 1\n",
    "models_to_keep = []\n",
    "for m in models:\n",
    "    n = len(out_df_ME[out_df_ME['Model']==m])\n",
    "    if n >= ens_members_needed:\n",
    "        models_to_keep.append(m)\n",
    "\n",
    "out_df_ME = out_df_ME[out_df_ME['Model'].isin(models_to_keep)]\n",
    "\n",
    "out_df_ME.to_csv('Outputs/Crossing_years_multi_ensemble_mems_for_box_plot_{r}yr_rolling_{e}_{t}C_thresh.csv'.format(r=window, e=exp, t=temp_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d40607-34ac-4fc2-a258-1640588feab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out_df_ME.Model.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d947c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp == 'ssp126':\n",
    "    out_df_ME.dropna(inplace=True)\n",
    "    \n",
    "\n",
    "models = list(set(out_df_ME['Model']))\n",
    "\n",
    "ensemble_members = [out_df_ME[out_df_ME['Model']==model].shape[0] for model in models]\n",
    "\n",
    "ensemble_members = [np.max(out_df_ME[out_df_ME['Model']==model]['gap']) - np.min(out_df_ME[out_df_ME['Model']==model]['gap']) for model in models]\n",
    "\n",
    "ensemble_members = pd.DataFrame({'model':models,'members':ensemble_members})\n",
    "\n",
    "ensemble_members = ensemble_members.sort_values('members').iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c41f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot\n",
    "\n",
    "vectors = [out_df_ME[out_df_ME['Model']==m]['gap'] for m in models]\n",
    "means = np.array([list(v)[0] for v in vectors])\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,5))\n",
    "\n",
    "ax.boxplot(vectors,positions=np.arange(len(vectors)),whis=[0,100],\n",
    "           showmeans=True,medianprops={'linewidth':0}, vert=True,\n",
    "            meanprops={'marker':'o',\n",
    "              'markerfacecolor':'r',\n",
    "              'markeredgecolor':'r'})\n",
    "\n",
    "mm_shift = 2\n",
    "\n",
    "ax.boxplot(means,positions=[len(vectors)+mm_shift],widths=0.5,\n",
    "           showmeans=True,\n",
    "           whis=[0,100],\n",
    "           medianprops={'linewidth':0},\n",
    "           meanprops={'marker':'o',\n",
    "                      'markersize':10,\n",
    "                      'markerfacecolor':'b',\n",
    "                      'markeredgecolor':'b'},\n",
    "          vert=True)\n",
    "\n",
    "print(np.nanmean(means))\n",
    "ax.set_xlim(-0.5,len(vectors)+mm_shift+1)\n",
    "ax.set_xticklabels(list(models)+['Multimodel\\nMean'],rotation=90)\n",
    "ax.set_ylabel(f'Years later crossing {temp_thresh}째C',fontsize='x-large')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20500914-1dc7-4ba8-9974-1277f0d92542",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_models = pd.DataFrame({'Model': models,\n",
    "                               'Ensemble_members_count': None}).set_index('Model')\n",
    "for model in ordered_models.index:\n",
    "    count = len(out_df_ME[out_df_ME['Model']==model]['Ensemble_member'].unique())\n",
    "    ordered_models['Ensemble_members_count'][model] = count\n",
    "\n",
    "single_mem_models = ordered_models[ordered_models['Ensemble_members_count']==1]\n",
    "multi_mem_models = ordered_models[ordered_models['Ensemble_members_count'] != 1]\n",
    "\n",
    "#sort alphabetically for each category\n",
    "single_mem_models.sort_index(inplace=True)\n",
    "single_mem_models = single_mem_models[::-1]\n",
    "multi_mem_models.sort_index(inplace=True)\n",
    "multi_mem_models = multi_mem_models[::-1]\n",
    "#recombine\n",
    "ordered_models = pd.concat([multi_mem_models, single_mem_models])\n",
    "\n",
    "#print(ordered_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b925c-a5f0-440d-bb47-3a181856bf48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceec222-f433-4a88-8e0e-670ab9ddd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine both plots\n",
    "\n",
    " \n",
    "#models = ensemble_members['model']\n",
    "\n",
    "vectors = [out_df_ME[out_df_ME['Model']==m]['gap'] for m in ordered_models.index]\n",
    "means = np.array([list(v)[0] for v in vectors])\n",
    "multi_mem_vectors = [out_df_ME[out_df_ME['Model']==m]['gap'] for m in multi_mem_models.index]\n",
    "single_mem_vectors = [out_df_ME[out_df_ME['Model']==m]['gap'] for m in single_mem_models.index]\n",
    "\n",
    "\n",
    "fig, (ax2, ax1) = plt.subplots(1,2,figsize=(12,7), gridspec_kw={'width_ratios': [1, 2.5]})\n",
    "plt.rcParams['font.size'] = '12'\n",
    "\n",
    "ax1.axhline(2, color='k',ls='--')\n",
    "ax1.axhline(1.5, color='k',ls='--')\n",
    "for i in range(len(blues)):\n",
    "    ax1.plot(years[i], blues[i],\n",
    "             c='b', alpha=0.5, linewidth=0.5)\n",
    "    ax1.plot(years[i], reds[i], \n",
    "             c='r', alpha=0.5, linewidth=0.5)\n",
    "\n",
    "\n",
    "## add observations:\n",
    "ax1.plot(Obs_df['year'], Obs_df['world_tas'], c='blue', \n",
    "         linestyle='--', label='Observations')\n",
    "ax1.plot(Obs_df['year'], Obs_df['no_arctic_tas'], c='red', \n",
    "         linestyle='--', label='Observations\\nWithout AA')\n",
    "\n",
    "# legend_without_duplicate_labels(ax1,fontsize='large')\n",
    "\n",
    "ax1.plot([],[],lw=0.9,label='CMIP6 Models',color='b')\n",
    "ax1.plot([],[],lw=0.9,label='CMIP6 Models\\nWithout AA',color='r')\n",
    "\n",
    "ax1.legend(fontsize='large')\n",
    "\n",
    "\n",
    "ax1.set_xlim(2000,2065)\n",
    "ax1.set_ylim(0.7, 2.7)\n",
    "\n",
    "ax1.set_ylabel('Temperature Anomaly (째C)',fontsize='x-large', labelpad=10)\n",
    "ax1.set_xlabel('Year',fontsize='x-large')\n",
    "ax1.yaxis.tick_right()\n",
    "ax1.yaxis.set_label_position('right')\n",
    "\n",
    "#ax1.yaxis.tick_left()\n",
    "#ax1.yaxis.set_label_position('left')\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "ax2.boxplot(vectors,positions=np.arange(len(vectors)),whis=[0,100],\n",
    "           showmeans=True,medianprops={'linewidth':0}, vert=False,\n",
    "            meanprops={'marker':'o', \n",
    "                       'markersize':5,\n",
    "              'markerfacecolor':'r',\n",
    "              'markeredgecolor':'r'})\n",
    "mm_shift = 2\n",
    "ax2.boxplot(means,positions=[len(vectors)+mm_shift],widths=0.5,\n",
    "           showmeans=True,\n",
    "           whis=[0,100],\n",
    "           medianprops={'linewidth':0},\n",
    "           meanprops={'marker':'o',\n",
    "                      'markersize':10,\n",
    "                      'markerfacecolor':'black',\n",
    "                      'markeredgecolor':'black'},\n",
    "          vert=False)\n",
    "\n",
    "\n",
    "ax2.set_ylim(-0.5,len(vectors)+mm_shift+1)\n",
    "ax2.set_xlabel(f'Years later\\ncrossing {temp_thresh}째C',fontsize='x-large')\n",
    "\n",
    "ax2.tick_params(axis=\"x\",direction=\"out\", which='both', top=True, labeltop=False, bottom=True, labelbottom=True)\n",
    "ax2.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax2.grid(color = 'gray', linestyle = '--', linewidth = 0.5)\n",
    "ax2.set_yticklabels(list(ordered_models.index)+['Multimodel\\nMean'],rotation=0, fontsize='small')  \n",
    "\n",
    "markersize=100\n",
    "marker='^'\n",
    "for thresh in [1.5,2]:\n",
    "    \n",
    "    out_df = out_dfs[thresh]\n",
    "    \n",
    "    x,y = np.nanmean(out_df['No_arctic_crossing_year']), np.nanmean(out_df['World_crossing_year'])\n",
    "    z = stats.sem(out_df['gap'], nan_policy='omit')\n",
    "    x_e, y_e = stats.sem(out_df['No_arctic_crossing_year'], nan_policy='omit'), stats.sem(out_df['World_crossing_year'], nan_policy='omit')\n",
    "    ax1.scatter(x,thresh,color='r',marker=marker,s=markersize)\n",
    "    ax1.scatter(y,thresh,color='b',marker=marker,s=markersize)\n",
    "    \n",
    "    print(f'Temp Thresh: {thresh}')\n",
    "    print(x, x_e, y, y_e)\n",
    "    print('gap: ', x-y, '+-', z)\n",
    "    \n",
    "\n",
    "#plt.text(0, 1, 'b', fontsize='x-large', transform=ax.transAxes)\n",
    "         \n",
    "# fig = plt.gcf()\n",
    "\n",
    "\n",
    "\n",
    "ax1.set_title('b', weight='bold', fontsize='x-large', loc='left', pad=15)\n",
    "ax2.set_title('a', weight='bold', fontsize='x-large', loc='left', pad=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('Figures/Combined_{}.png'.format(exp), dpi=300)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c3ab3-3ff8-417d-b3e6-b976471ad3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(blues))\n",
    "print(len(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765c5b9-3598-4b3a-8731-546740f418d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2050\n",
    "def ratio_of_intermodel_spread(year):\n",
    "    w_e = stats.sem(M_df[M_df['year']==year]['adjusted_world_tas_anom'])\n",
    "    na_e = stats.sem(M_df[M_df['year']==year]['adjusted_no_arctic_tas_anom'])\n",
    "    print(w_e, na_e)\n",
    "    print(((w_e-na_e)/na_e))\n",
    "\n",
    "#for year in np.arange(2040, 2095, 1):\n",
    "#    ratio_of_intermodel_spread(year)\n",
    "ratio_of_intermodel_spread(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe006de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd3a96-cc77-480b-aceb-88e2acd624dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
